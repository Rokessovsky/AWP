{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Environment Set-up"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import cv2\n",
    "import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Image pre-processing"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Extract frames from videos"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Path to the parent directory\n",
    "path = 'AWP/SAM_Clustering/videos'\n",
    "frames_path = 'AWP/SAM_Clustering/frames'\n",
    "\n",
    "# Make sure the frame directory exists\n",
    "os.makedirs(frames_path, exist_ok=True)\n",
    "\n",
    "# List to store video names\n",
    "video_names = []\n",
    "\n",
    "# Global variables for frame extraction\n",
    "NUM_FRAMES = 9  # number of frames to extract from each video\n",
    "TIME_INTERVAL = 0.1  # time interval in seconds between each extracted frame\n",
    "\n",
    "# Loop through all directories and subdirectories\n",
    "for subdir, dirs, files in os.walk(path):\n",
    "    # Check if directory is not empty\n",
    "    if files:\n",
    "        # Get the last part of directory which is considered as the video number\n",
    "        video_number = os.path.basename(subdir)\n",
    "        # Sort files to ensure naming is in order\n",
    "        files.sort()\n",
    "        # Enumerate files with 1-based index and construct name\n",
    "        for index, file in enumerate(files, start=1):\n",
    "            video_name = f\"{video_number}_{index}_mp4\"\n",
    "            video_names.append(video_name)\n",
    "\n",
    "            # Load the video using OpenCV\n",
    "            video_path = os.path.join(subdir, file)\n",
    "            vidcap = cv2.VideoCapture(video_path)\n",
    "\n",
    "            # Get video frames per second (fps)\n",
    "            fps = vidcap.get(cv2.CAP_PROP_FPS)\n",
    "            # Calculate the frame skip based on desired time interval\n",
    "            frame_skip = int(fps * TIME_INTERVAL)\n",
    "\n",
    "            # Get total frames\n",
    "            total_frames = vidcap.get(cv2.CAP_PROP_FRAME_COUNT)\n",
    "            # Calculate the start and end frame for the middle few 5%\n",
    "            start_frame = int(total_frames * 0.45)\n",
    "            end_frame = int(total_frames * 0.50)\n",
    "\n",
    "            success, image = vidcap.read()\n",
    "            frame_count = 0\n",
    "            extracted_frames = 0\n",
    "            while success:\n",
    "                # Check if this frame is one of the frames we want to extract\n",
    "                if frame_count % frame_skip == 0 and extracted_frames < NUM_FRAMES and start_frame <= frame_count <= end_frame:\n",
    "                    frame_name = f\"{video_name}_{extracted_frames + 1}.png\"\n",
    "                    frame_path = os.path.join(frames_path, frame_name)\n",
    "                    cv2.imwrite(frame_path, image)\n",
    "\n",
    "                    # Add the following code to display the image:\n",
    "                    img = mpimg.imread(frame_path)\n",
    "                    imgplot = plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "                    plt.show()\n",
    "\n",
    "                    extracted_frames += 1\n",
    "                success, image = vidcap.read()\n",
    "                frame_count += 1\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Segementation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def show_mask(mask, ax, random_color=False):\n",
    "    if random_color:\n",
    "        color = np.concatenate([np.random.random(3), np.array([0.6])], axis=0)\n",
    "    else:\n",
    "        color = np.array([30/255, 144/255, 255/255, 0.6])\n",
    "    h, w = mask.shape[-2:]\n",
    "    mask_image = mask.reshape(h, w, 1) * color.reshape(1, 1, -1)\n",
    "    ax.imshow(mask_image)\n",
    "\n",
    "def show_points(coords, labels, ax, marker_size=375):\n",
    "    pos_points = coords[labels==1]\n",
    "    neg_points = coords[labels==0]\n",
    "    ax.scatter(pos_points[:, 0], pos_points[:, 1], color='green', marker='*', s=marker_size, edgecolor='white', linewidth=1.25)\n",
    "    ax.scatter(neg_points[:, 0], neg_points[:, 1], color='red', marker='*', s=marker_size, edgecolor='white', linewidth=1.25)\n",
    "\n",
    "def show_box(box, ax):\n",
    "    x0, y0 = box[0], box[1]\n",
    "    w, h = box[2] - box[0], box[3] - box[1]\n",
    "    ax.add_patch(plt.Rectangle((x0, y0), w, h, edgecolor='green', facecolor=(0,0,0,0), lw=2))\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from segment_anything import sam_model_registry, SamPredictor\n",
    "\n",
    "sam_checkpoint = \"sam_vit_h_4b8939.pth\"\n",
    "model_type = \"vit_h\"\n",
    "\n",
    "device = \"cuda\"\n",
    "\n",
    "sam = sam_model_registry[model_type](checkpoint=sam_checkpoint)\n",
    "sam.to(device=device)\n",
    "\n",
    "predictor = SamPredictor(sam)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "masks_path = 'AWP/SAM_Clustering/masks'\n",
    "# Make sure the frame directory exists\n",
    "os.makedirs(masks_path, exist_ok=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def process_image(image_path):\n",
    "    image = cv2.imread(image_path)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    predictor.set_image(image)\n",
    "\n",
    "    input_point = np.array([[1000, 630], [950, 570], [1060, 600]])\n",
    "    input_label = np.array([1, 1, 1])\n",
    "\n",
    "    masks, scores, logits = predictor.predict(\n",
    "        point_coords=input_point,\n",
    "        point_labels=input_label,\n",
    "        multimask_output=True,\n",
    "    )\n",
    "\n",
    "    mask_input = logits[np.argmax(scores), :, :]  # Choose the model's best mask\n",
    "\n",
    "    masks, _, _ = predictor.predict(\n",
    "        point_coords=input_point,\n",
    "        point_labels=input_label,\n",
    "        mask_input=mask_input[None, :, :],\n",
    "        multimask_output=False,\n",
    "    )\n",
    "\n",
    "    masks.shape\n",
    "\n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.imshow(image)\n",
    "    show_mask(masks, plt.gca())\n",
    "    show_points(input_point, input_label, plt.gca())\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "    # Apply the mask to the image\n",
    "    masked_image = image * masks[0][:, :, None]  # If masks has more than 1 dimension, select the relevant one\n",
    "\n",
    "    # Convert the masked image back to BGR color scheme for saving\n",
    "    masked_image = cv2.cvtColor(masked_image.astype(np.uint8), cv2.COLOR_RGB2BGR)\n",
    "\n",
    "    # Save the masked image\n",
    "    cv2.imwrite(os.path.join(masks_path, f'mask_{os.path.basename(image_path)}'), masked_image)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# The directory where the frames are stored\n",
    "frame_dir = '/content/frames'\n",
    "\n",
    "\n",
    "# Process each image in the frame directory\n",
    "for image_file in os.listdir(frame_dir):\n",
    "    image_path = os.path.join(frame_dir, image_file)\n",
    "    if os.path.isfile(image_path):\n",
    "        process_image(image_path)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Fine-tuning"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Clustering"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "# for loading/processing the images\n",
    "from tensorflow.keras.utils import load_img\n",
    "from tensorflow.keras.utils import img_to_array\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "import cv2\n",
    "\n",
    "# models\n",
    "from tensorflow.keras.applications.efficientnet import preprocess_input\n",
    "from tensorflow.keras.applications import EfficientNetB7\n",
    "\n",
    "# clustering and dimension reduction\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "\n",
    "# image augmentation\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# for everything else\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# from random import randint\n",
    "# import pandas as pd\n",
    "# import pickle\n",
    "# from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "path = r\"/content/masks\"\n",
    "# change the working directory to the path where the images are located\n",
    "os.chdir(path)\n",
    "\n",
    "# this list holds all the image filename\n",
    "flowers = []\n",
    "\n",
    "# creates a ScandirIterator aliased as files\n",
    "with os.scandir(path) as files:\n",
    "    # loops through each file in the directory\n",
    "    for file in files:\n",
    "        if file.name.endswith('.png'):\n",
    "            # adds only the image files to the flowers list\n",
    "            flowers.append(file.name)\n",
    "\n",
    "model = EfficientNetB7(include_top=False, pooling='avg', weights='imagenet')\n",
    "\n",
    "# Define our example data generator\n",
    "datagen = ImageDataGenerator(\n",
    "    # rotation_range=2,\n",
    "    # width_shift_range=0.1,\n",
    "    # height_shift_range=0.1,\n",
    "    # horizontal_flip=True,\n",
    "    # brightness_range=[0.7, 1.3],\n",
    ")\n",
    "\n",
    "def load_images(file):\n",
    "    # load the image as a 600x600 array\n",
    "    img = load_img(file, target_size=(600, 600))\n",
    "    # convert from 'PIL.Image.Image' to numpy array\n",
    "    img = np.array(img)\n",
    "    # reshape the data for the model reshape(num_of_samples, dim 1, dim 2, channels)\n",
    "    reshaped_img = img.reshape(1, 600, 600 ,3)\n",
    "    return reshaped_img\n",
    "\n",
    "# Load all images into memory\n",
    "image_list = []\n",
    "for flower in flowers:\n",
    "    try:\n",
    "        img = load_images(flower)\n",
    "        image_list.append(img)\n",
    "    except:\n",
    "        print(\"Error loading image: \", flower)\n",
    "\n",
    "images = np.vstack(image_list)\n",
    "\n",
    "# Prepare iterator\n",
    "iterator = datagen.flow(images, batch_size=1, shuffle=False)\n",
    "\n",
    "# Extract features for each image\n",
    "data = {}\n",
    "for i, batch in enumerate(iterator):\n",
    "    if i >= len(flowers):  # ImageDataGenerator indefinitely produces batches\n",
    "        break\n",
    "    img = batch[0]  # we have batch_size=1, so there's only one image in the batch\n",
    "    img = preprocess_input(img)\n",
    "    features = model.predict(np.array([img]), use_multiprocessing=True)\n",
    "    data[flowers[i]] = features\n",
    "\n",
    "\n",
    "# get a list of the filenames\n",
    "filenames = np.array(list(data.keys()))\n",
    "\n",
    "# get a list of just the features\n",
    "feat = np.array(list(data.values()))\n",
    "\n",
    "# reshape so that there are 210 samples of 2560 vectors\n",
    "feat = feat.reshape(-1,2560)\n",
    "\n",
    "# reduce the amount of dimensions in the feature vector\n",
    "pca = PCA(n_components=12, random_state=22)\n",
    "pca.fit(feat)\n",
    "x = pca.transform(feat)\n",
    "\n",
    "# cluster feature vectors\n",
    "hclust = AgglomerativeClustering(n_clusters=6)\n",
    "hclust.fit(x)\n",
    "\n",
    "# holds the cluster id and the images { id: [images] }\n",
    "groups = {}\n",
    "for file, cluster in zip(filenames,hclust.labels_):\n",
    "    if cluster not in groups.keys():\n",
    "        groups[cluster] = []\n",
    "        groups[cluster].append(file)\n",
    "    else:\n",
    "        groups[cluster].append(file)\n",
    "\n",
    "# function that lets you view a cluster (based on identifier)\n",
    "def view_cluster(cluster):\n",
    "    plt.figure(figsize = (25,25));\n",
    "    # gets the list of filenames for a cluster\n",
    "    files = groups[cluster]\n",
    "    # only allow up to 30 images to be shown at a time\n",
    "    if len(files) > 30:\n",
    "        print(f\"Clipping cluster size from {len(files)} to 30\")\n",
    "        files = files[:29]\n",
    "    # plot each image in the cluster\n",
    "    for index, file in enumerate(files):\n",
    "        plt.subplot(10,10,index+1);\n",
    "        img = load_img(file)\n",
    "        img = np.array(img)\n",
    "        plt.imshow(img)\n",
    "        plt.axis('off')\n",
    "\n",
    "# Loop through the clusters\n",
    "for cluster in groups.keys():\n",
    "    view_cluster(cluster)\n",
    "    plt.show()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
